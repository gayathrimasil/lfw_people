{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras-tuner --upgrade\n\nfrom time import time\nimport logging\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport keras_tuner \nimport seaborn as sbn\n\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras.layers import Conv2D, Flatten, Dense, Dropout \nfrom keras.models import Sequential\nfrom kerastuner import RandomSearch\nfrom kerastuner.engine.hyperparameters import HyperParameters\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nprint(__doc__)","metadata":{"id":"AEYWH4jtgu7Z","outputId":"3db7e246-65a0-4c6f-c6fb-97746adb4150","execution":{"iopub.status.busy":"2022-06-01T14:26:50.308776Z","iopub.execute_input":"2022-06-01T14:26:50.309096Z","iopub.status.idle":"2022-06-01T14:27:01.934028Z","shell.execute_reply.started":"2022-06-01T14:26:50.309057Z","shell.execute_reply":"2022-06-01T14:27:01.933096Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# # #############################################################################\n# Download the data, if not already on disk and load it as numpy arrays\n\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n\n# introspect the images arrays to find the shapes (for plotting)\nn_samples, h, w = lfw_people.images.shape\n\n# for machine learning we use the 2 data directly (as relative pixel\n# positions info is ignored by this model)\nX = lfw_people.data\nn_features = X.shape[1]\n\n# the label to predict is the id of the person\ny = lfw_people.target\ntarget_names = lfw_people.target_names\nn_classes = target_names.shape[0]\n\nprint(\"Total dataset size:\")\nprint(\"Sample size: %d\" % n_samples, h, w)\nprint(\"Features: %d\" % n_features)\nprint(\"Total Labels: %d\" % n_classes)\nprint(\"\")\nprint(\"Target Name and no of sample images:\")\nfor i in range(len(lfw_people.target_names)):   \n    print(\"{} has {} samples\".format(lfw_people.target_names[i], (y == i).sum()))\n\n# #############################################################################\n# Plotting the images of the persons from the dataset\nfig, ax = plt.subplots(4, 4)\nplt.subplots_adjust(wspace=0.8, hspace=0.5)\n\nfor i, axi in enumerate(ax.flat):\n    axi.imshow(lfw_people.images[i])\n    axi.set(xticks=[], yticks=[], xlabel=lfw_people.target_names[lfw_people.target[i]])\nplt.show()","metadata":{"id":"bTMh3RkdzHEE","outputId":"32cb654c-529b-4d1c-c2c8-ca1503f6f0b5","execution":{"iopub.status.busy":"2022-06-01T14:27:01.935970Z","iopub.execute_input":"2022-06-01T14:27:01.936245Z","iopub.status.idle":"2022-06-01T14:27:02.721936Z","shell.execute_reply.started":"2022-06-01T14:27:01.936213Z","shell.execute_reply":"2022-06-01T14:27:02.720965Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# Checking for missing values\ndf=pd.DataFrame(lfw_people.data)\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:27:02.723436Z","iopub.execute_input":"2022-06-01T14:27:02.724548Z","iopub.status.idle":"2022-06-01T14:27:02.749800Z","shell.execute_reply.started":"2022-06-01T14:27:02.724494Z","shell.execute_reply":"2022-06-01T14:27:02.748427Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# Checking data type\nprint(df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:27:02.751770Z","iopub.execute_input":"2022-06-01T14:27:02.752578Z","iopub.status.idle":"2022-06-01T14:27:02.760766Z","shell.execute_reply.started":"2022-06-01T14:27:02.752537Z","shell.execute_reply":"2022-06-01T14:27:02.759972Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"#############################################################################\n# Split data into a training, validation and testing set\n\nX_cv, X_test, y_cv, y_test = train_test_split(X,y,test_size=0.10,train_size=0.90, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_cv,y_cv,test_size = 0.10,train_size =0.90, random_state=15)\n\n","metadata":{"id":"rCKJK2oFhNMJ","execution":{"iopub.status.busy":"2022-06-01T14:27:02.762211Z","iopub.execute_input":"2022-06-01T14:27:02.762748Z","iopub.status.idle":"2022-06-01T14:27:02.788287Z","shell.execute_reply.started":"2022-06-01T14:27:02.762695Z","shell.execute_reply":"2022-06-01T14:27:02.787296Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# #############################################################################\n# Scaling and reshaping the data\n\nX_train /= 255\nX_val /= 255\nX_test /= 255\n\nX_train=X_train.reshape(X_train.shape[0], h, w, 1)\nX_val=X_val.reshape(X_val.shape[0], h, w, 1)\nX_test=X_test.reshape(X_test.shape[0], h, w, 1)","metadata":{"id":"Qom3cN4mhQUc","outputId":"a6ac2b03-0028-492a-9ff4-8f7a3bef4d0b","execution":{"iopub.status.busy":"2022-06-01T14:27:02.790318Z","iopub.execute_input":"2022-06-01T14:27:02.791073Z","iopub.status.idle":"2022-06-01T14:27:02.800522Z","shell.execute_reply.started":"2022-06-01T14:27:02.791019Z","shell.execute_reply":"2022-06-01T14:27:02.799554Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# Builind function for hyperparameter tuning\n\ndef build_model(hp):  \n  cnnmodel = keras.Sequential([keras.layers.Conv2D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n                                                   kernel_size=hp.Choice('conv_1_kernel', values = [3,5]), strides=(1, 1),\n                                                   activation='relu',input_shape=(h,w,1)\n                                                   ),\n                               keras.layers.Conv2D(filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n                                                   kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),strides=(1, 1),\n                                                   activation='relu'\n                                                   ),\n                               keras.layers.Flatten(),\n                               keras.layers.Dense(units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n                                                  activation='relu'\n                                                  ),\n#                                keras.layers.Dropout(0.5),\n                               keras.layers.Dense(n_classes, activation='softmax')\n                              ])\n\n  \n  cnnmodel.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n  \n  return cnnmodel","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:27:02.802844Z","iopub.execute_input":"2022-06-01T14:27:02.803823Z","iopub.status.idle":"2022-06-01T14:27:02.816696Z","shell.execute_reply.started":"2022-06-01T14:27:02.803774Z","shell.execute_reply":"2022-06-01T14:27:02.814868Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# Using randomserach to identify best fitting hyperparameter\ntuner = keras_tuner.RandomSearch(build_model,objective='val_accuracy',\n                                 max_trials=5, directory='output', project_name=\"CourseWork_FaceRec\")","metadata":{"id":"bzfSS69oslMX","execution":{"iopub.status.busy":"2022-06-01T14:27:02.818795Z","iopub.execute_input":"2022-06-01T14:27:02.819149Z","iopub.status.idle":"2022-06-01T14:27:02.916357Z","shell.execute_reply.started":"2022-06-01T14:27:02.819102Z","shell.execute_reply":"2022-06-01T14:27:02.915189Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# Searching to get best model\ntuner.search(X_train,y_train,epochs=3,validation_data=(X_val, y_val))\nbestmodel=tuner.get_best_models(num_models=1)[0]\nbestmodel.summary()","metadata":{"id":"5qum46eT-nMl","outputId":"b4e3c389-7715-4398-c584-a6ef87bb074c","execution":{"iopub.status.busy":"2022-06-01T14:27:02.917709Z","iopub.execute_input":"2022-06-01T14:27:02.917940Z","iopub.status.idle":"2022-06-01T14:27:03.455398Z","shell.execute_reply.started":"2022-06-01T14:27:02.917911Z","shell.execute_reply":"2022-06-01T14:27:03.454362Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"bestmodel.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), initial_epoch=3)","metadata":{"id":"43Yg1Dw_NXqp","outputId":"859a02ee-ed81-47ec-e2fe-5bf81477ff31","execution":{"iopub.status.busy":"2022-06-01T14:27:03.458357Z","iopub.execute_input":"2022-06-01T14:27:03.458638Z","iopub.status.idle":"2022-06-01T14:27:32.489064Z","shell.execute_reply.started":"2022-06-01T14:27:03.458584Z","shell.execute_reply":"2022-06-01T14:27:32.487918Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"# Validating the model with validation dataset\ntest_loss, test_acc = bestmodel.evaluate(X_val, y_val, verbose=2)\nprint('\\n Test accuracy:', test_acc)","metadata":{"id":"CoMPtsGOOo2Y","outputId":"a16850c7-23b2-490b-97cf-046a87c1daf0","execution":{"iopub.status.busy":"2022-06-01T14:27:32.490477Z","iopub.execute_input":"2022-06-01T14:27:32.490746Z","iopub.status.idle":"2022-06-01T14:27:32.670188Z","shell.execute_reply.started":"2022-06-01T14:27:32.490713Z","shell.execute_reply":"2022-06-01T14:27:32.669231Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# Predicting the model with test data\ncnn_y_pred=bestmodel.predict(X_test)\ncnn_y_pred=np.argmax(cnn_y_pred, axis=1)\ncnn_y_pred\n\n## Confusion Matrix \ncnn_con_matrix = tf.math.confusion_matrix(y_test,cnn_y_pred)\n\n%matplotlib inline\nplt.figure(figsize=(10,10))\nplt.title('Confusion Matrix for CNN')\nsbn.heatmap(cnn_con_matrix, cmap=\"OrRd\", annot=True,\n            cbar_kws={\"label\":\"Color Bar\"}, fmt='d',\n            xticklabels=target_names, yticklabels=target_names)\nplt.xlabel('Predicted Value')\nplt.ylabel('True Value')\nplt.show()\n\nprint(classification_report(y_test, cnn_y_pred, target_names=target_names))\n\n# #############################################################################\n# Qualitative evaluation of the predictions using matplotlib\n\ndef plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n        plt.title(titles[i], size=12)\n        plt.xticks(())\n        plt.yticks(())\n\n\n# plot the result of the prediction on a portion of the test set\n\ndef title(cnn_y_pred, y_test, target_names, i):\n    pred_name = target_names[cnn_y_pred[i]].rsplit(' ', 1)[-1]\n    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n\nprediction_titles = [title(cnn_y_pred, y_test, target_names, i)\n                     for i in range(cnn_y_pred.shape[0])]\n\nplot_gallery(X_test, prediction_titles, h, w)\n\n","metadata":{"id":"MRCyQmElRfcF","outputId":"43b7d2dc-dbd9-46ba-b108-cfd4ec9e196c","execution":{"iopub.status.busy":"2022-06-01T14:27:32.671946Z","iopub.execute_input":"2022-06-01T14:27:32.672273Z","iopub.status.idle":"2022-06-01T14:27:34.038156Z","shell.execute_reply.started":"2022-06-01T14:27:32.672228Z","shell.execute_reply":"2022-06-01T14:27:34.037079Z"},"trusted":true},"execution_count":120,"outputs":[]}]}