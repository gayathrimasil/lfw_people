{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from time import time\nimport logging\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sbn\n\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nprint(__doc__)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:03:43.395688Z","iopub.execute_input":"2022-06-01T14:03:43.396002Z","iopub.status.idle":"2022-06-01T14:03:43.405365Z","shell.execute_reply.started":"2022-06-01T14:03:43.395968Z","shell.execute_reply":"2022-06-01T14:03:43.404143Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Display progress logs on stdout\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n\n# #############################################################################\n# Download the data, if not already on disk and load it as numpy arrays\n\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n\n# introspect the images arrays to find the shapes (for plotting)\nn_samples, h, w = lfw_people.images.shape\n\n# for machine learning we use the 2 data directly (as relative pixel\n# positions info is ignored by this model)\nX=pd.DataFrame(lfw_people.data)\nn_features = X.shape[1]\n\n# the label to predict is the id of the person\ny = lfw_people.target\ntarget_names = lfw_people.target_names\nn_classes = target_names.shape[0]\n\nprint(\"Total dataset size:\")\nprint(\"Sample size: %d\" % n_samples)\nprint(\"Features: %d\" % n_features)\nprint(\"Total Labels: %d\" % n_classes)\nprint(\"\")\nprint(\"Target Name and no of sample images:\")\nfor i in range(len(lfw_people.target_names)):   \n    print(\"{} has {} samples\".format(lfw_people.target_names[i], (y == i).sum()))\n\n# #############################################################################\n# Plotting no of images per person from the dataset\nfig, ax = plt.subplots(4, 4)\nplt.subplots_adjust(wspace=0.8, hspace=0.5)\n\nfor i, axi in enumerate(ax.flat):\n    axi.imshow(lfw_people.images[i], cmap='gray')\n    axi.set(xticks=[], yticks=[], xlabel=lfw_people.target_names[lfw_people.target[i]])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:03:43.409195Z","iopub.execute_input":"2022-06-01T14:03:43.409820Z","iopub.status.idle":"2022-06-01T14:03:44.406855Z","shell.execute_reply.started":"2022-06-01T14:03:43.409780Z","shell.execute_reply":"2022-06-01T14:03:44.405695Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Checking for missing values\nX.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:03:44.408658Z","iopub.execute_input":"2022-06-01T14:03:44.408902Z","iopub.status.idle":"2022-06-01T14:03:44.427828Z","shell.execute_reply.started":"2022-06-01T14:03:44.408872Z","shell.execute_reply":"2022-06-01T14:03:44.426325Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Checking data type\nprint(X.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:03:44.428882Z","iopub.execute_input":"2022-06-01T14:03:44.429105Z","iopub.status.idle":"2022-06-01T14:03:44.438302Z","shell.execute_reply.started":"2022-06-01T14:03:44.429058Z","shell.execute_reply":"2022-06-01T14:03:44.437467Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# #############################################################################\n# Split into a training set and a test set using a stratified k fold\n\n# split into a training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# scaling the data\nscaler=StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:03:44.439921Z","iopub.execute_input":"2022-06-01T14:03:44.440155Z","iopub.status.idle":"2022-06-01T14:03:44.540559Z","shell.execute_reply.started":"2022-06-01T14:03:44.440125Z","shell.execute_reply":"2022-06-01T14:03:44.539627Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# #############################################################################\n# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n# dataset): unsupervised feature extraction / dimensionality reduction\nn_components = 150\n\nprint(\"Extracting the top %d eigenfaces from %d faces\"\n      % (n_components, X_train.shape[0]))\nt0 = time()\npca = PCA(n_components=n_components, svd_solver='randomized',\n          whiten=True).fit(X_train)\nprint(\"done in %0.3fs\" % (time() - t0))\n\neigenfaces = pca.components_.reshape((n_components, h, w))\n\nprint(\"Projecting the input data on the eigenfaces orthonormal basis\")\nt0 = time()\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\nprint(\"done in %0.3fs\" % (time() - t0))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:03:44.541671Z","iopub.execute_input":"2022-06-01T14:03:44.542428Z","iopub.status.idle":"2022-06-01T14:03:45.787968Z","shell.execute_reply.started":"2022-06-01T14:03:44.542393Z","shell.execute_reply":"2022-06-01T14:03:45.786679Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"###############################################################################\n# Optimizing hyperparameter for MultiLayer Perceptron\n# hidden_layer_sizes=(10,15)\nactivation = ['identity','logistic','tanh','relu']\nsolver = ['adam', 'sgd']\nlearning_rate = ['constant', 'invscaling', 'adaptive']\nparam_grid={'activation': activation,\n            'solver':solver,\n            'learning_rate': learning_rate,\n            }\nprint(f'The hyperparamters are : {param_grid}')\n\nprint('Fitting the classifier to the training set')\nprint('')\nt0 = time()\n\nmlp = MLPClassifier(hidden_layer_sizes=(15,10))\nmlp_Grid = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, verbose=10, n_jobs=-1)\nmlp_Grid.fit(X_train_pca, y_train)\n\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(f'Best estimator found by grid search: {mlp_Grid.best_params_}')\n\n\n# #############################################################################\n# Quantitative evaluation of the model quality on the test set\nprint(\"Predicting people's names on the test set\")\nt0 = time()\ny_predicted_mlp=mlp_Grid.predict(X_test_pca)\n\n# Confusion Matrix \ncon_matrix_mlp=confusion_matrix(y_test, y_predicted_mlp)\n%matplotlib inline\nplt.figure(figsize=(10,10))\nplt.title('Confusion Matrix for Multilayer Perceptron')\nsbn.heatmap(con_matrix_mlp, cmap=\"Greens\", annot=True,\n            cbar_kws={\"label\":\"Color Bar\"}, fmt='d',\n            xticklabels=target_names, yticklabels=target_names)\nplt.xlabel('Predicted Value')\nplt.ylabel('True Value')\nplt.show()\n\nprint(\"\\ndone in %0.3fs\" % (time() - t0))\nprint(classification_report(y_test, y_predicted_mlp, target_names=target_names))\n\n# #############################################################################\n# Qualitative evaluation of the predictions using matplotlib\ndef plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n        plt.title(titles[i], size=12)\n        plt.xticks(())\n        plt.yticks(())\n\n\n# plot the result of the prediction on a portion of the test set\ndef title(y_predicted_mlp, y_test, target_names, i):\n    pred_name = target_names[y_predicted_mlp[i]].rsplit(' ', 1)[-1]\n    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n\nprediction_titles = [title(y_predicted_mlp, y_test, target_names, i)\n                     for i in range(y_predicted_mlp.shape[0])]\nplot_gallery(X_test, prediction_titles, h, w)\n\n\n# plot the gallery of the most significative eigenfaces\n\neigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\nplot_gallery(eigenfaces, eigenface_titles, h, w)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:03:45.792110Z","iopub.execute_input":"2022-06-01T14:03:45.794392Z","iopub.status.idle":"2022-06-01T14:04:12.555729Z","shell.execute_reply.started":"2022-06-01T14:03:45.794350Z","shell.execute_reply":"2022-06-01T14:04:12.554279Z"},"trusted":true},"execution_count":14,"outputs":[]}]}